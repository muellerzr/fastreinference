{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "66c1bd66-779c-4c25-923b-54863cd87e4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# default_exp performer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f70cd344-f05c-4753-ae2c-6067f736026e",
   "metadata": {},
   "source": [
    "# Performer\n",
    "> The base class for performing inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "85aae097-e811-4d5d-8bd3-59c9cca5205a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide\n",
    "from nbdev.showdoc import show_doc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "43b813cb-b290-4c73-bcc5-652a164c9be9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "from fastreinference.configure import InferenceConfiguration, ManagerType\n",
    "from fastcore.transform import Transform, Pipeline, _get_name\n",
    "\n",
    "import torch\n",
    "from fastai.learner import Learner\n",
    "\n",
    "from contextlib import contextmanager"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "54402a26-64f8-445e-96c9-9bae4677060d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def _print_fastai_transform(transform:Transform):\n",
    "    \"Prints information about a `transform`\"\n",
    "    information_string = \"Transform Name: \"\n",
    "    information_string += f\"`{transform.__module__}.{_get_name(transform)}`\\n\"\n",
    "    information_string += f\"Supported input types:\\n\"\n",
    "    for dispatch in list(transform.encodes.funcs.d.keys()):\n",
    "        information_string += f\"  - `{dispatch.__module__}.{_get_name(dispatch)}`\\n\"\n",
    "    information_string += \"Has different behavior on test set:\\n\"\n",
    "    information_string += \"  - \"\n",
    "    if transform.split_idx is None:\n",
    "        if hasattr(transform, \"before_call\"):\n",
    "            information_string += \"Yes\"\n",
    "        else:\n",
    "            information_string += \"No\"\n",
    "    elif transform.split_idx == 0:\n",
    "        information_string += \"Yes, is not performed\"\n",
    "    print(information_string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e7179ee5-1e8e-4f37-a032-930786aaba6e",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "module 'fastai' has no attribute 'learn'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Input \u001b[0;32mIn [5]\u001b[0m, in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m#export\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m \u001b[38;5;28;01mclass\u001b[39;00m \u001b[38;5;21;01mPerformer\u001b[39;00m:\n\u001b[1;32m      3\u001b[0m     _pipeline_events \u001b[38;5;241m=\u001b[39m [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtype_transforms\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mitem_transforms\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbatch_transforms\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m      4\u001b[0m     _in_training_state \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n",
      "Input \u001b[0;32mIn [5]\u001b[0m, in \u001b[0;36mPerformer\u001b[0;34m()\u001b[0m\n\u001b[1;32m     29\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mitem_transforms \u001b[38;5;241m=\u001b[39m transform_pipelines[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mitem_transforms\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m     30\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbatch_transforms \u001b[38;5;241m=\u001b[39m transform_pipelines[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbatch_transforms\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m     32\u001b[0m \u001b[38;5;129m@classmethod\u001b[39m\n\u001b[0;32m---> 33\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfrom_learner\u001b[39m(\u001b[38;5;28mcls\u001b[39m, learner:\u001b[43mfastai\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlearn\u001b[49m\u001b[38;5;241m.\u001b[39mLearner):\n\u001b[1;32m     34\u001b[0m     \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m     35\u001b[0m \u001b[38;5;124;03m    Builds a `Performer` from a fastai `Learner`\u001b[39;00m\n\u001b[1;32m     36\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m     37\u001b[0m     model \u001b[38;5;241m=\u001b[39m learner\u001b[38;5;241m.\u001b[39mmodel\n",
      "\u001b[0;31mAttributeError\u001b[0m: module 'fastai' has no attribute 'learn'"
     ]
    }
   ],
   "source": [
    "#export\n",
    "class Performer:\n",
    "    _pipeline_events = [\"type_transforms\", \"item_transforms\", \"batch_transforms\"]\n",
    "    _in_training_state = False\n",
    "    def __init__(self, model, transform_pipelines:dict = None):\n",
    "        \"\"\"\n",
    "        An encapsulating inference module.\n",
    "        \n",
    "        `transform_pipeline` should be a dictionary of general transform pipelines\n",
    "          with keys: `type_transforms`, `item_transforms`, and `batch_transforms`\n",
    "          \n",
    "        Transforms do not need to be fastai transforms, but be cognizant that if mixing is performed,\n",
    "          you should be wary of the fastai dispatch system and ensure that the pipeline can continue.\n",
    "          \n",
    "        Item and Batch transforms should either be all fastai transforms or all custom transforms.\n",
    "        \"\"\"\n",
    "        self.model = model\n",
    "        if transform_pipelines is None:\n",
    "            print(\"\"\"Warning: No `transform_pipelines` were passed to `Performer.__init__`. \n",
    "            Please set them with `Performer.configure_pipelines` before performing inference!\"\"\")\n",
    "        else:\n",
    "            missing_events = []\n",
    "            for key in _pipeline_events:\n",
    "                if key not in transform_pipelines.keys():\n",
    "                    missing_events += key\n",
    "            if len(missing_events) > 0:\n",
    "                raise ValueError(f'Passed `pipes` dictionary is missing one or more keys: {missing_events}')\n",
    "            self.type_transforms = transform_pipelines[\"type_transforms\"]\n",
    "            self.item_transforms = transform_pipelines[\"item_transforms\"]\n",
    "            self.batch_transforms = transform_pipelines[\"batch_transforms\"]\n",
    "            \n",
    "    @classmethod\n",
    "    def from_learner(cls, learner:Learner):\n",
    "        \"\"\"\n",
    "        Builds a `Performer` from a fastai `Learner`\n",
    "        \"\"\"\n",
    "        model = learner.model\n",
    "        transform_pipelines = {}\n",
    "        transform_pipelines[\"type_transforms\"] = learner.dls.train.tfms\n",
    "        transform_pipelines[\"item_transforms\"] = learner.dls.after_item\n",
    "        transform_pipelines[\"batch_transforms\"] = learner.dls.after_batch\n",
    "        cls(model, transform_pipelines)\n",
    "        \n",
    "        \n",
    "    def _are_transforms_fastai(self, transforms:list, transform_kind:str):\n",
    "        \"\"\"\n",
    "        Checks if all transforms in `transforms` are from fastai. Will raise an error if there is mismatching.\n",
    "        \"\"\"\n",
    "        all_from_fastai = all(\n",
    "            isinstance(transform, Transform) \n",
    "            for transform in transforms\n",
    "        )\n",
    "        any_from_fastai = any(\n",
    "            isinstance(transform, Transform)\n",
    "            for transform in transforms\n",
    "        )\n",
    "        \n",
    "        if (any_from_fastai and not all_from_fastai) or (not all_from_fastai and any_from_fastai):\n",
    "            raise ValueError(f'''All passed {transform_kind} are not of the same kind.\n",
    "            Please use either fastai transforms or custom transforms.\n",
    "            \n",
    "            fastai Transforms:\n",
    "              {[t for t in transforms if isinstance(transform, Transform)]}\n",
    "            Custom Transforms:\n",
    "              {[t for t in transforms if not isinstance(transform, Transform)]}''')\n",
    "            \n",
    "        if not any_from_fastai: \n",
    "            return False\n",
    "        if all_from_fastai:\n",
    "            return True\n",
    "    \n",
    "    # Should this be broken up given the single-responsibility principal?\n",
    "    # Performer should only be getting batches and applying events\n",
    "    # Need a new DL type or pipeline-type class\n",
    "    def configure_pipelines(self, type_transforms:list, item_transforms:list, batch_transforms:list):\n",
    "        \"\"\"\n",
    "        Override and configure all data preparation pipelines based on lists of transforms.\n",
    "        Transforms do not need to be fastai transforms, but be cognizant that if mixing is performed,\n",
    "          you should be wary of the fastai dispatch system and ensure that the pipeline can continue.\n",
    "          \n",
    "        Item and Batch transform lists should either be all fastai transforms or all custom transforms.\n",
    "        \"\"\"\n",
    "        self.type_transforms = type_transforms\n",
    "        if self._are_transforms_fastai(item_transforms, \"`item_transforms`\"):\n",
    "            self.item_transforms = Pipeline(item_transforms)\n",
    "        else:\n",
    "            self.item_transforms = item_transforms\n",
    "        if self._are_transforms_fastai(batch_transforms, \"`batch_transforms`\"):\n",
    "            self.batch_transforms = Pipeline(batch_transforms)\n",
    "        else:\n",
    "            self.batch_transforms = batch_transforms\n",
    "        print(\"Successfully configured transform pipelines\")\n",
    "        \n",
    "    def describe_pipeline_of_type(self, pipeline_type:str):\n",
    "        \"\"\"\n",
    "        Describes a configured transform pipeline.\n",
    "        Can be a string of \"type\", \"item\", or \"batch\".\n",
    "        \n",
    "        Transforms are then described as:\n",
    "        ```\n",
    "        Transform Name: `Resize`\n",
    "        Supported input types: \n",
    "          - `PIL.Image.Image`\n",
    "          - `fastai.vision.core.TensorBBox`\n",
    "          - `fastai.vision.core.TensorPoint`\n",
    "        Has different behavior on test set: \n",
    "          - Yes\n",
    "        ```\n",
    "        if it is a fastai transform, else:\n",
    "        ```\n",
    "        Transform Name: `function_name`\n",
    "        ```\n",
    "        \"\"\"\n",
    "        if not any(pipeline_name == kind for kind in [\"type\", \"item\", \"batch\"]):\n",
    "            raise ValueError(f\"Invalid value passed for `pipeline_name`: {pipeline_name}. Must be one of 'type', 'item', or 'batch'.\")\n",
    "        transforms = getattr(self, f\"{pipeline_name}_transforms\")\n",
    "        print('-'*36)\n",
    "        if isinstance(transforms, Pipeline):\n",
    "            for transform in transforms: \n",
    "                _print_fastai_transform(transform)\n",
    "                print('-'*36)\n",
    "        else:\n",
    "            for transform in transforms:\n",
    "                print(f\"Transform Name: `{_get_name(transform)}`\")\n",
    "                print('-'*36)\n",
    "                \n",
    "    def _call_pipeline(self, inputs, pipeline_type:str):\n",
    "        \"Runs `self.{pipeline_type}` on inputs\"\n",
    "        pipeline = getattr(self, pipeline_type)\n",
    "        if isinstance(pipeline, Pipeline):\n",
    "            return pipeline(inputs)\n",
    "        else:\n",
    "            for transform in pipeline: \n",
    "                inputs = transform(inputs)\n",
    "            return inputs\n",
    "        \n",
    "    @contextmanager\n",
    "    def in_training_state(self):\n",
    "        \"\"\"\n",
    "        Context manager that sets data preprocessing to apply training augmentation while in use\n",
    "        \"\"\"\n",
    "        original_split_idxs = []\n",
    "        for event in self._pipeline_events:\n",
    "            pipe = getattr(self, event)\n",
    "            if isinstance(pipe, Pipeline):\n",
    "                original_split_idxs.append(pipe.split_idx)\n",
    "                setattr(pipe, \"split_idx\", 0)\n",
    "        yield\n",
    "        for event in self._event_pipeline_events:\n",
    "            pipe = getattr(self, event)\n",
    "            if isinstance(pipe, Pipeline):\n",
    "                setattr(pipe, \"split_idx\", original_split_idxs[0])\n",
    "                original_split_idxs.pop(0)\n",
    "    \n",
    "    @staticmethod\n",
    "    def _get_context_manager(manager_type:ManagerType):\n",
    "        if manager_type == \"no_grad\": \n",
    "            return torch.no_grad\n",
    "        elif manager_type == \"inference\": \n",
    "            return torch.inference_mode\n",
    "        else:\n",
    "            raise NotImplementedError(f\"Context manager of type {manager_type} is not supported. Please use a valid `ManagerType`.\")\n",
    "        \n",
    "    # def _do_inference(self, config):\n",
    "        \n",
    "                \n",
    "    def predict(self, inputs, config, **kwargs):\n",
    "        if isinstance(inputs, fastai.data.load.DataLoader) or isinstance(fastai.data.load.TfmdDL):\n",
    "            dataloader = inputs\n",
    "        elif isinstance(inputs, torch.utils.data.DataLoader):\n",
    "            dataloader = inputs\n",
    "        else:\n",
    "            for event in self._pipeline_events:\n",
    "                inputs = self._call_pipeline(inputs, event)\n",
    "            dataloader = torch.utils.data.DataLoader(inputs, **kwargs)\n",
    "            \n",
    "        if config.context != ManagerType.NONE:\n",
    "            with get_context_manager(config.context)():\n",
    "                return self._do_inference(dataloader, config)\n",
    "        else:\n",
    "            return self._do_inference(dataloader, config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "cf9c2769-7327-457a-8387-816cd436dafa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "<h4 id=\"Performer.describe_pipeline_of_type\" class=\"doc_header\"><code>Performer.describe_pipeline_of_type</code><a href=\"__main__.py#L65\" class=\"source_link\" style=\"float:right\">[source]</a></h4>\n",
       "\n",
       "> <code>Performer.describe_pipeline_of_type</code>(**`pipeline_type`**:`str`)\n",
       "\n",
       "Describes a configured transform pipeline.\n",
       "Can be a string of \"type\", \"item\", or \"batch\".\n",
       "\n",
       "Transforms are then described as:\n",
       "```\n",
       "Transform Name: `Resize`\n",
       "Supported input types: \n",
       "  - `PIL.Image.Image`\n",
       "  - `fastai.vision.core.TensorBBox`\n",
       "  - `fastai.vision.core.TensorPoint`\n",
       "Has different behavior on test set: \n",
       "  - Yes\n",
       "```\n",
       "if it is a fastai transform, else:\n",
       "```\n",
       "Transform Name: `function_name`\n",
       "```"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "show_doc(Performer.describe_pipeline_of_type)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "812369cf-b337-42a0-96b2-f143548e840f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
