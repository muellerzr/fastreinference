---

title: Configure


keywords: fastai
sidebar: home_sidebar

summary: "The foundational event system for `Performer` based on fastai `Callback`s"
description: "The foundational event system for `Performer` based on fastai `Callback`s"
nb_path: "00_configure.ipynb"
---
<!--

#################################################
### THIS FILE WAS AUTOGENERATED! DO NOT EDIT! ###
#################################################
# file to edit: 00_configure.ipynb
# command to build the docs after a change: nbdev_build_docs

-->

<div class="container" id="notebook-container">
        
    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">

<div class="output_wrapper">
<div class="output">

<div class="output_area">


<div class="output_markdown rendered_html output_subarea ">
<h2 id="DeviceType" class="doc_header"><code>DeviceType</code><a href="" class="source_link" style="float:right">[source]</a></h2><blockquote><p><code>Enum</code> = [CPU, CUDA]</p>
</blockquote>
<p>An enumeration.</p>

</div>

</div>

</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">

<div class="output_wrapper">
<div class="output">

<div class="output_area">


<div class="output_markdown rendered_html output_subarea ">
<h4 id="get_default_device" class="doc_header"><code>get_default_device</code><a href="https://github.com/muellerzr/fastreinference/tree/master/fastreinference/configure.py#L22" class="source_link" style="float:right">[source]</a></h4><blockquote><p><code>get_default_device</code>()</p>
</blockquote>
<p>Returns <a href="/fastreinference/configure.html#DeviceType.CPU"><code>DeviceType.CPU</code></a> if GPU is not available, else <a href="/fastreinference/configure.html#DeviceType.CUDA"><code>DeviceType.CUDA</code></a></p>

</div>

</div>

</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">

<div class="output_wrapper">
<div class="output">

<div class="output_area">


<div class="output_markdown rendered_html output_subarea ">
<h2 id="ManagerType" class="doc_header"><code>ManagerType</code><a href="" class="source_link" style="float:right">[source]</a></h2><blockquote><p><code>Enum</code> = [NO_GRAD, NONE, INFERENCE]</p>
</blockquote>
<p>An enumeration.</p>

</div>

</div>

</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">

<div class="output_wrapper">
<div class="output">

<div class="output_area">


<div class="output_markdown rendered_html output_subarea ">
<h4 id="no_grad" class="doc_header"><code>no_grad</code><a href="" class="source_link" style="float:right">[source]</a></h4><p>Run with <code>torch.no_grad</code></p>

</div>

</div>

</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">

<div class="output_wrapper">
<div class="output">

<div class="output_area">


<div class="output_markdown rendered_html output_subarea ">
<h4 id="inference_mode" class="doc_header"><code>inference_mode</code><a href="" class="source_link" style="float:right">[source]</a></h4><p>Run with <code>torch.inference_mode</code></p>

</div>

</div>

</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">

<div class="output_wrapper">
<div class="output">

<div class="output_area">


<div class="output_markdown rendered_html output_subarea ">
<h4 id="none" class="doc_header"><code>none</code><a href="" class="source_link" style="float:right">[source]</a></h4><p>Keep all gradients and apply no context managers</p>

</div>

</div>

</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">

<div class="output_wrapper">
<div class="output">

<div class="output_area">


<div class="output_markdown rendered_html output_subarea ">
<h2 id="InferenceConfiguration" class="doc_header"><code>class</code> <code>InferenceConfiguration</code><a href="https://github.com/muellerzr/fastreinference/tree/master/fastreinference/configure.py#L39" class="source_link" style="float:right">[source]</a></h2><blockquote><p><code>InferenceConfiguration</code>() :: <code>ABC</code></p>
</blockquote>
<p>The foundational class for customizing behaviors during inference.</p>
<p>There are three methods available that must be implemented:</p>
<ul>
<li><code>after_drawn_batch</code></li>
<li><code>gather_predictions</code></li>
<li><code>decoding_values</code></li>
</ul>
<p>If an implementation should stay to its default behavior, do the following:</p>
<ul>
<li><code>event_name(self, *args): return super().event_name(*args)</code></li>
</ul>
<p>Where <code>event_name</code> is any of the three events listed above</p>
<p>A <code>context</code> can be set with a <a href="/fastreinference/configure.html#ManagerType"><code>ManagerType</code></a> for what type of context manager should be ran at inference time</p>

</div>

</div>

</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">

<div class="output_wrapper">
<div class="output">

<div class="output_area">


<div class="output_markdown rendered_html output_subarea ">
<h4 id="InferenceConfiguration.gather_predictions" class="doc_header"><code>InferenceConfiguration.gather_predictions</code><a href="https://github.com/muellerzr/fastreinference/tree/master/fastreinference/configure.py#L68" class="source_link" style="float:right">[source]</a></h4><blockquote><p><code>InferenceConfiguration.gather_predictions</code>(<strong><code>model</code></strong>, <strong><code>batch</code></strong>)</p>
</blockquote>
<p>Performs inference with <code>model</code> on <code>batch</code>.
Any specific inference decorators such as <code>no_grad</code> or <code>inference_mode</code> is done in <a href="/fastreinference/performer.html#Performer"><code>Performer</code></a>.</p>
<p>Default implementation is <code>model(*batch)</code>.</p>

</div>

</div>

</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="c1"># Since there would only be one level, easy to track where and how</span>
</pre></div>

    </div>
</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="k">class</span> <span class="nc">ImageClassifierConfiguration</span><span class="p">(</span><span class="n">InferenceConfiguration</span><span class="p">):</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">vocab</span><span class="p">):</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">vocab</span> <span class="o">=</span> <span class="n">vocab</span>
    <span class="k">def</span> <span class="nf">after_drawn_batch</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">batch</span><span class="p">):</span> <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="n">after_drawn_batch</span><span class="p">(</span><span class="n">batch</span><span class="p">)</span>
    <span class="k">def</span> <span class="nf">gather_predictions</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">model</span><span class="p">,</span> <span class="n">batch</span><span class="p">):</span>
        <span class="k">return</span> <span class="n">model</span><span class="p">(</span><span class="o">*</span><span class="n">batch</span><span class="p">)</span>
    <span class="k">def</span> <span class="nf">decoding_values</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">values</span><span class="p">):</span>
        <span class="n">preds</span> <span class="o">=</span> <span class="n">values</span><span class="o">.</span><span class="n">argmax</span><span class="p">(</span><span class="n">dim</span><span class="o">=-</span><span class="mi">1</span><span class="p">)</span>
        <span class="n">decoded_preds</span> <span class="o">=</span> <span class="p">[</span><span class="bp">self</span><span class="o">.</span><span class="n">vocab</span><span class="p">[</span><span class="n">p</span><span class="p">]</span> <span class="k">for</span> <span class="n">p</span> <span class="ow">in</span> <span class="n">preds</span><span class="p">]</span>
        <span class="k">return</span> <span class="p">{</span><span class="s2">&quot;classes&quot;</span><span class="p">:</span><span class="n">decoded_preds</span><span class="p">,</span> <span class="s2">&quot;probabilities&quot;</span><span class="p">:</span><span class="n">preds</span><span class="p">}</span>
</pre></div>

    </div>
</div>
</div>

</div>
    {% endraw %}

</div>
 

