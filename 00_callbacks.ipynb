{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# default_exp callbacks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Callbacks\n",
    "\n",
    "> The foundational Callback event system for `Performer`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide\n",
    "from nbdev.showdoc import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "from abc import ABC, abstractmethod"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "class InferenceCallback(ABC):\n",
    "    \"\"\"\n",
    "    The foundational class for customizing behaviors during inference.\n",
    "    \n",
    "    There are three methods available that must be implemented:\n",
    "      - `after_drawn_batch`\n",
    "      - `gather_predictions`\n",
    "      - `decoding_values`\n",
    "      \n",
    "    If an implementation should stay to its default behavior, do the following:\n",
    "      - `event_name(self, *args): return super().event_name(*args)`\n",
    "      \n",
    "    Where `event_name` is any of the three events listed above\n",
    "    \"\"\"\n",
    "    @abstractmethod\n",
    "    def after_drawn_batch(self, batch):\n",
    "        \"\"\"\n",
    "        Called immediatly after a batch has been drawn from the `DataLoader`.\n",
    "        Any final adjustments to the batch before being sent to the model should be done here.\n",
    "        \n",
    "        Default implementation is to return `batch`.\n",
    "        \"\"\"\n",
    "        return batch\n",
    "    \n",
    "    @abstractmethod\n",
    "    def gather_predictions(self, model, batch): \n",
    "        \"\"\"\n",
    "        Performs inference with `model` on `batch`.\n",
    "        Any specific inference decorators such as `no_grad` or `inference_mode` is done in `Performer`.\n",
    "        \n",
    "        Default implementation is `model(*batch)`.\n",
    "        \"\"\"\n",
    "        return model(*batch)\n",
    "    \n",
    "    @abstractmethod\n",
    "    def decoding_values(self, values): \n",
    "        \"\"\"\n",
    "        Called after predictions have been gathered on a `batch`.\n",
    "        Any specific class decoding and final datatype preparation should be done here.\n",
    "        \n",
    "        Default implementation is to return `values`.\n",
    "        \"\"\"\n",
    "        return values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "<h2 id=\"InferenceCallback\" class=\"doc_header\"><code>class</code> <code>InferenceCallback</code><a href=\"\" class=\"source_link\" style=\"float:right\">[source]</a></h2>\n",
       "\n",
       "> <code>InferenceCallback</code>() :: `ABC`\n",
       "\n",
       "The foundational class for customizing behaviors during inference.\n",
       "\n",
       "There are three methods available that must be implemented:\n",
       "  - `after_drawn_batch`\n",
       "  - `gather_predictions`\n",
       "  - `decoding_values`\n",
       "  \n",
       "If an implementation should stay to its default behavior, do the following:\n",
       "  - `event_name(self, *args): return super().event_name(*args)`\n",
       "  \n",
       "Where `event_name` is one of the three events listed above"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "show_doc(InferenceCallback)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "<h4 id=\"InferenceCallback.gather_predictions\" class=\"doc_header\"><code>InferenceCallback.gather_predictions</code><a href=\"__main__.py#L26\" class=\"source_link\" style=\"float:right\">[source]</a></h4>\n",
       "\n",
       "> <code>InferenceCallback.gather_predictions</code>(**`model`**, **`batch`**)\n",
       "\n",
       "Performs inference with `model` on `batch`.\n",
       "Any specific inference decorators such as `no_grad` or `inference_mode` is done in `Performer`.\n",
       "\n",
       "Default implementation is `model(*batch)`."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "show_doc(InferenceCallback.gather_predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Why abstract: Force users to think about if this is how they want their code in prod to be ran\n",
    "# Since there would only be one level, easy to track where and how"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ImageClassifierCallback(InferenceCallback):\n",
    "    def after_drawn_batch(self, batch):\n",
    "        print(batch)\n",
    "        return batch\n",
    "    def gather_predictions(self, *args): return super().gather_predictions(*args)\n",
    "    def decoding_values(self, *args): return super().decoding_values(*args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ImageClassifierCallback(InferenceCallback):\n",
    "    def __init__(self, vocab):\n",
    "        self.vocab = vocab\n",
    "    def gather_predictions(self, model, batch):\n",
    "        return model(*batch)\n",
    "    def decoding_values(self, values):\n",
    "        preds = values.argmax(dim=-1)\n",
    "        decoded_preds = [self.vocab[p] for p in preds]\n",
    "        return {\"classes\":decoded_preds, \"probabilities\":preds}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Performer should only do the following automatically:\n",
    "#  Device placement of both model and batch\n",
    "#  Pull a batch from the DataLoader\n",
    "#  From item(s), create a new `DataLoader`\n",
    "#  Whether we run in torch.no_grad or not\n",
    "\n",
    "#  Be configurable to allow for training_augmentation or test_augmentation if we are a fastai dataloader\n",
    "#  Maybe as a context_manager? e.g. with Performer.in_training_state(): ... do inference. Sets it in Performer so we don't need it in the DataLoader.\n",
    "#    Should raise a warning if the used `DataLoader` isn't one from fastai with this\n",
    "\n",
    "# Maybe a `from_pipes` method?"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
